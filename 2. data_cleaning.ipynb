{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc74dfc",
   "metadata": {},
   "source": [
    "# 数据清理 (Data Cleaning)\n",
    "\n",
    "本笔记本涵盖了 `processed_data.csv` 数据的清理过程，旨在为分类任务做准备。\n",
    "主要步骤包括：\n",
    "1. 加载数据\n",
    "2. 文本预处理（去除停用词、标点符号、特殊字符）\n",
    "3. **去除与标签过于相似的词汇**（防止模型直接通过标签词进行预测，即“数据泄露”）\n",
    "4. 保存清理后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47933d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# 下载必要的 NLTK 数据包 (如果尚未下载)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a3ab6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据总行数: 1641\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Paper Name</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Insulin resistance is a condition characterize...</td>\n",
       "      <td>Brain insulin resistance mediated cognitive im...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>substrate 1 (IRS1)/PI3K/AKT and IGF-1 receptor...</td>\n",
       "      <td>Brain insulin resistance mediated cognitive im...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prolactin is a pituitary anterior lobe hormone...</td>\n",
       "      <td>Hyperprolactinemia and Brain Health: Exploring...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lecanemab is an amyloid-targeted antibody indi...</td>\n",
       "      <td>Severe Persistent Urinary Retention Following ...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Glycoprotein 88 (GP88) is a secreted biomarker...</td>\n",
       "      <td>An Impedimetric Immunosensor for Progranulin D...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  Insulin resistance is a condition characterize...   \n",
       "1  substrate 1 (IRS1)/PI3K/AKT and IGF-1 receptor...   \n",
       "2  Prolactin is a pituitary anterior lobe hormone...   \n",
       "3  Lecanemab is an amyloid-targeted antibody indi...   \n",
       "4  Glycoprotein 88 (GP88) is a secreted biomarker...   \n",
       "\n",
       "                                          Paper Name                Label  \n",
       "0  Brain insulin resistance mediated cognitive im...  Alzheimer's Disease  \n",
       "1  Brain insulin resistance mediated cognitive im...  Alzheimer's Disease  \n",
       "2  Hyperprolactinemia and Brain Health: Exploring...  Alzheimer's Disease  \n",
       "3  Severe Persistent Urinary Retention Following ...  Alzheimer's Disease  \n",
       "4  An Impedimetric Immunosensor for Progranulin D...  Alzheimer's Disease  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 加载数据\n",
    "df = pd.read_csv('processed_data.csv')\n",
    "\n",
    "# 查看数据前几行\n",
    "print(f\"数据总行数: {len(df)}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66ea757c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基础停用词总数: 198\n",
      "需要掩码处理的词汇数: 16\n"
     ]
    }
   ],
   "source": [
    "# 2. 定义需要去除的词汇和掩码策略\n",
    "\n",
    "# 获取 NLTK 的英文停用词\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# 定义与标签（疾病名称）高度相关的词汇，用于掩码处理\n",
    "# 标签包括: Alzheimer's disease, Frontotemporal dementia, Lewy body dementia, Mild cognitive impairment, Parkinson's disease\n",
    "label_related_words = {\n",
    "    'alzheimer', 'alzheimers', 'ad', # Alzheimer's disease\n",
    "    'frontotemporal', 'ftd', # Frontotemporal dementia\n",
    "    'lewy', 'lbd', 'dlb', # Lewy body dementia\n",
    "    'parkinson', 'parkinsons', 'pd', # Parkinson's disease\n",
    "    'dementia', 'disease', 'syndrome', 'disorder', # 通用医学后缀\n",
    "    'vascular',  # Vascular dementia\n",
    "}\n",
    "\n",
    "# 注意：我们不再将这些词加入停用词表进行删除，而是在后续步骤中替换为掩码\n",
    "print(f\"基础停用词总数: {len(stop_words)}\")\n",
    "print(f\"需要掩码处理的词汇数: {len(label_related_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13eb1cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始文本: Background: Patients with Alzheimer's disease (AD) often show cognitive impairment. 123 http://test.com\n",
      "清理后文本: background patient [DISEASE] [DISEASE] [DISEASE] often show cognitive impairment\n"
     ]
    }
   ],
   "source": [
    "# 3. 定义数据清理函数\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # 1. 转为小写\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. 去除 URL, 邮箱, 若有HTML标签也可以去除\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # 3. 去除特殊字符和数字 (保留字母和空格)\n",
    "    # 这里的正则 [^a-zA-Z\\s] 表示除了字母和空白字符外的所有字符都会被替换为空格\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "    \n",
    "    # 4. 分词并去除停用词、垃圾字符、词形还原\n",
    "    words = text.split()\n",
    "    cleaned_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        # 去除过短的单词 (比如长度为1的单字母，除了'a', 'i'等常用词外通常意义不大，这里一并过滤)\n",
    "        if len(word) < 2:\n",
    "            continue\n",
    "            \n",
    "        lemma_word = lemmatizer.lemmatize(word)\n",
    "        \n",
    "        # 优先检查是否需要掩码 (Before stopword check to ensure we mask even if it somehow was a stopword, though unlikely)\n",
    "        if word in label_related_words or lemma_word in label_related_words:\n",
    "            cleaned_words.append('[DISEASE]')\n",
    "            continue\n",
    "\n",
    "        # 检查是否在停用词表中 (使用基础 stop_words)\n",
    "        if word not in stop_words and lemma_word not in stop_words:\n",
    "            cleaned_words.append(lemma_word)\n",
    "            \n",
    "    return \" \".join(cleaned_words)\n",
    "\n",
    "# 测试清理函数\n",
    "sample_text = \"Background: Patients with Alzheimer's disease (AD) often show cognitive impairment. 123 http://test.com\"\n",
    "print(\"原始文本:\", sample_text)\n",
    "print(\"清理后文本:\", clean_text(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6950ed6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清理后为空的行数: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Cleaned_Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Insulin resistance is a condition characterize...</td>\n",
       "      <td>insulin resistance condition characterized att...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>substrate 1 (IRS1)/PI3K/AKT and IGF-1 receptor...</td>\n",
       "      <td>substrate irs pi akt igf receptor igf irs pi p...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prolactin is a pituitary anterior lobe hormone...</td>\n",
       "      <td>prolactin pituitary anterior lobe hormone play...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lecanemab is an amyloid-targeted antibody indi...</td>\n",
       "      <td>lecanemab amyloid targeted antibody indicated ...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Glycoprotein 88 (GP88) is a secreted biomarker...</td>\n",
       "      <td>glycoprotein gp secreted biomarker overexpress...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  Insulin resistance is a condition characterize...   \n",
       "1  substrate 1 (IRS1)/PI3K/AKT and IGF-1 receptor...   \n",
       "2  Prolactin is a pituitary anterior lobe hormone...   \n",
       "3  Lecanemab is an amyloid-targeted antibody indi...   \n",
       "4  Glycoprotein 88 (GP88) is a secreted biomarker...   \n",
       "\n",
       "                                     Cleaned_Content                Label  \n",
       "0  insulin resistance condition characterized att...  Alzheimer's Disease  \n",
       "1  substrate irs pi akt igf receptor igf irs pi p...  Alzheimer's Disease  \n",
       "2  prolactin pituitary anterior lobe hormone play...  Alzheimer's Disease  \n",
       "3  lecanemab amyloid targeted antibody indicated ...  Alzheimer's Disease  \n",
       "4  glycoprotein gp secreted biomarker overexpress...  Alzheimer's Disease  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 应用清理函数到 Content 列\n",
    "\n",
    "# 我们可以选择清理 'Content' 列，也可以顺便清理 'Paper Name'\n",
    "# 这里主要关注 'Content'，并将其保存到新的一列 'Cleaned_Content'\n",
    "df['Cleaned_Content'] = df['Content'].apply(clean_text)\n",
    "\n",
    "# 检查清理后的空值 (如果有些行只包含停用词，清理后可能为空)\n",
    "print(\"清理后为空的行数:\", (df['Cleaned_Content'] == \"\").sum())\n",
    "\n",
    "# 删除清理后内容为空的行\n",
    "df = df[df['Cleaned_Content'] != \"\"]\n",
    "\n",
    "# 重置索引\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 查看清理前后的对比\n",
    "df[['Content', 'Cleaned_Content', 'Label']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "658876f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清理后的数据已保存至: cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "# 5. 保存清理后的数据\n",
    "output_file = 'cleaned_data.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"清理后的数据已保存至: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
