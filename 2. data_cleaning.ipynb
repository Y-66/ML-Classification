{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc74dfc",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "This notebook covers the cleaning process for `processed_data.csv`, preparing it for classification tasks.\n",
    "Key steps include:\n",
    "1. Loading data\n",
    "2. Text preprocessing (removing stopwords, punctuation, special characters)\n",
    "3. **Removing words highly similar to labels** (preventing data leakage where models predict directly using label words)\n",
    "4. Saving cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47933d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK packages (if not already downloaded)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3ab6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据总行数: 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Paper Name</th>\n",
       "      <th>Label</th>\n",
       "      <th>Document Type</th>\n",
       "      <th>Affiliations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Insulin resistance is a condition characterize...</td>\n",
       "      <td>Brain insulin resistance mediated cognitive im...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "      <td>Review</td>\n",
       "      <td>Department of Pharmaceutical Sciences, Maharsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prolactin is a pituitary anterior lobe hormone...</td>\n",
       "      <td>Hyperprolactinemia and Brain Health: Exploring...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "      <td>Review</td>\n",
       "      <td>School of Pharmacy, Hubei University of Chines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lecanemab is an amyloid-targeted antibody indi...</td>\n",
       "      <td>Severe Persistent Urinary Retention Following ...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "      <td>Article</td>\n",
       "      <td>Department of Psychiatry, Duke University Scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Glycoprotein 88 (GP88) is a secreted biomarker...</td>\n",
       "      <td>An Impedimetric Immunosensor for Progranulin D...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "      <td>Article</td>\n",
       "      <td>University of New Brunswick, Fredericton, NB, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disruption of the blood–brain barrier (BBB) ac...</td>\n",
       "      <td>Regulation of Blood–Brain Barrier Permeability...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "      <td>Review</td>\n",
       "      <td>Department of Pharmacology, Research Institute...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  Insulin resistance is a condition characterize...   \n",
       "1  Prolactin is a pituitary anterior lobe hormone...   \n",
       "2  Lecanemab is an amyloid-targeted antibody indi...   \n",
       "3  Glycoprotein 88 (GP88) is a secreted biomarker...   \n",
       "4  Disruption of the blood–brain barrier (BBB) ac...   \n",
       "\n",
       "                                          Paper Name                Label  \\\n",
       "0  Brain insulin resistance mediated cognitive im...  Alzheimer's Disease   \n",
       "1  Hyperprolactinemia and Brain Health: Exploring...  Alzheimer's Disease   \n",
       "2  Severe Persistent Urinary Retention Following ...  Alzheimer's Disease   \n",
       "3  An Impedimetric Immunosensor for Progranulin D...  Alzheimer's Disease   \n",
       "4  Regulation of Blood–Brain Barrier Permeability...  Alzheimer's Disease   \n",
       "\n",
       "  Document Type                                       Affiliations  \n",
       "0        Review  Department of Pharmaceutical Sciences, Maharsh...  \n",
       "1        Review  School of Pharmacy, Hubei University of Chines...  \n",
       "2       Article  Department of Psychiatry, Duke University Scho...  \n",
       "3       Article  University of New Brunswick, Fredericton, NB, ...  \n",
       "4        Review  Department of Pharmacology, Research Institute...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load Data\n",
    "df = pd.read_csv('processed_data.csv')\n",
    "\n",
    "# View first few rows\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ea757c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基础停用词总数: 198\n",
      "需要掩码处理的词汇数: 16\n"
     ]
    }
   ],
   "source": [
    "# 2. Define words to remove and masking strategy\n",
    "\n",
    "# Get NLTK English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define words highly related to labels (disease names) for masking\n",
    "# Labels include: Alzheimer's disease, Frontotemporal dementia, Lewy body dementia, Mild cognitive impairment, Parkinson's disease\n",
    "label_related_words = {\n",
    "    'alzheimer', 'alzheimers', 'ad', # Alzheimer's disease\n",
    "    'frontotemporal', 'ftd', # Frontotemporal dementia\n",
    "    'lewy', 'lbd', 'dlb', # Lewy body dementia\n",
    "    'parkinson', 'parkinsons', 'pd', # Parkinson's disease\n",
    "    'dementia', 'disease', 'syndrome', 'disorder', # Common medical suffixes\n",
    "    'vascular',  # Vascular dementia\n",
    "}\n",
    "\n",
    "# Note: We are no longer adding these words to stopwords for deletion, but replacing them with masks in subsequent steps\n",
    "print(f\"Total base stopwords: {len(stop_words)}\")\n",
    "print(f\"Number of words to mask: {len(label_related_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb1cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始文本: Background: Patients with Alzheimer's disease (AD) often show cognitive impairment. 123 http://test.com\n",
      "清理后文本: background patient [DISEASE] [DISEASE] [DISEASE] often show cognitive impairment\n"
     ]
    }
   ],
   "source": [
    "# 3. Define data cleaning function\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # 1. Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Remove URLs, emails, and HTML tags if any\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # 3. Remove special characters and numbers (keep letters and spaces)\n",
    "    # The regex [^a-zA-Z\\s] means replace all characters except letters and whitespace with a space\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "    \n",
    "    # 4. Tokenize and remove stopwords, junk characters, lemmatize\n",
    "    words = text.split()\n",
    "    cleaned_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Remove words that are too short (e.g. single letters, except 'a', 'i', etc., usually meaningless, filtered here)\n",
    "        if len(word) < 2:\n",
    "            continue\n",
    "            \n",
    "        lemma_word = lemmatizer.lemmatize(word)\n",
    "        \n",
    "        # Prioritize checking if masking is needed (Before stopword check to ensure we mask even if it somehow was a stopword, though unlikely)\n",
    "        if word in label_related_words or lemma_word in label_related_words:\n",
    "            cleaned_words.append('[DISEASE]')\n",
    "            continue\n",
    "\n",
    "        # Check if in stop words list (using base stop_words)\n",
    "        if word not in stop_words and lemma_word not in stop_words:\n",
    "            cleaned_words.append(lemma_word)\n",
    "            \n",
    "    return \" \".join(cleaned_words)\n",
    "\n",
    "# Test cleaning function\n",
    "sample_text = \"Background: Patients with Alzheimer's disease (AD) often show cognitive impairment. 123 http://test.com\"\n",
    "print(\"Original text:\", sample_text)\n",
    "print(\"Cleaned text:\", clean_text(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6950ed6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清理后为空的行数: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Cleaned_Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Insulin resistance is a condition characterize...</td>\n",
       "      <td>insulin resistance condition characterized att...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prolactin is a pituitary anterior lobe hormone...</td>\n",
       "      <td>prolactin pituitary anterior lobe hormone play...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lecanemab is an amyloid-targeted antibody indi...</td>\n",
       "      <td>lecanemab amyloid targeted antibody indicated ...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Glycoprotein 88 (GP88) is a secreted biomarker...</td>\n",
       "      <td>glycoprotein gp secreted biomarker overexpress...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disruption of the blood–brain barrier (BBB) ac...</td>\n",
       "      <td>disruption blood brain barrier bbb accompanies...</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  Insulin resistance is a condition characterize...   \n",
       "1  Prolactin is a pituitary anterior lobe hormone...   \n",
       "2  Lecanemab is an amyloid-targeted antibody indi...   \n",
       "3  Glycoprotein 88 (GP88) is a secreted biomarker...   \n",
       "4  Disruption of the blood–brain barrier (BBB) ac...   \n",
       "\n",
       "                                     Cleaned_Content                Label  \n",
       "0  insulin resistance condition characterized att...  Alzheimer's Disease  \n",
       "1  prolactin pituitary anterior lobe hormone play...  Alzheimer's Disease  \n",
       "2  lecanemab amyloid targeted antibody indicated ...  Alzheimer's Disease  \n",
       "3  glycoprotein gp secreted biomarker overexpress...  Alzheimer's Disease  \n",
       "4  disruption blood brain barrier bbb accompanies...  Alzheimer's Disease  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Apply cleaning function to Content column\n",
    "\n",
    "# We can choose to clean the 'Content' column, or 'Paper Name' as well\n",
    "# Here we focus on 'Content' and save it to a new column 'Cleaned_Content'\n",
    "df['Cleaned_Content'] = df['Content'].apply(clean_text)\n",
    "\n",
    "# Check for empty values after cleaning (rows might be empty if they contained only stopwords)\n",
    "print(\"Rows empty after cleaning:\", (df['Cleaned_Content'] == \"\").sum())\n",
    "\n",
    "# Remove rows that are empty after cleaning\n",
    "df = df[df['Cleaned_Content'] != \"\"]\n",
    "\n",
    "# Reset index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Compare before and after cleaning\n",
    "df[['Content', 'Cleaned_Content', 'Label']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658876f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清理后的数据已保存至: cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "# 5. Save cleaned data\n",
    "output_file = 'cleaned_data.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Cleaned data saved to: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
